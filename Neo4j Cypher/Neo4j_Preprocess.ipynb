{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import *\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess post\n",
    "# Id\tPostTypeId\tAcceptedAnswerId\tCreationDate\t\n",
    "# Score\tViewCount\tOwnerUserId\tTitle\tTags\tAnswerCount\tCommentCount\t\n",
    "bucket= []\n",
    "with open(\"/Users/chaizhizhi/Desktop/5338_data/Posts.tsv\") as post:\n",
    "        read_post = csv.reader(post, delimiter='\\t',quotechar='\"')\n",
    "        next(read_post)\n",
    "        for line in read_post:\n",
    "            temp = [\n",
    "                    line[0], #'Id'\n",
    "                    line[1], #'PostTypeId'\n",
    "                    line[2], # 'AcceptedAnswerId'\n",
    "                    line[3],#'CreationDate'\n",
    "                    line[5], #'ViewCount':\n",
    "                    line[6], #'OwnerUserId'\n",
    "                    line[7], #'Title'\n",
    "                    line[8],#'Tags'\n",
    "                    line[12]#'ParentId'\n",
    "            ]    \n",
    "            bucket.append(temp)\n",
    "        \n",
    "with open('/Users/chaizhizhi/Desktop/5338Assignment/Neo4jCypher/post.csv','w') as post:\n",
    "        write_post = csv.writer(post,delimiter=',',quotechar='\"')\n",
    "        header = ['Id','PostTypeId','AcceptedAnswerId','CreationDate','ViewCount','OwnerUserId','Title','Tags','ParentId']\n",
    "        write_post.writerow(header)\n",
    "        write_post.writerows(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess votes\n",
    "bucket = []\n",
    "with open(\"/Users/chaizhizhi/Desktop/5338_data/Votes.tsv\") as vote:\n",
    "        read_vote = csv.reader(vote, delimiter='\\t',quotechar='\"')\n",
    "        next(read_vote)\n",
    "        for row in read_vote:\n",
    "            # 拼装语句\n",
    "            temp = [\n",
    "                row[0], #Id': \n",
    "                row[1], # 'PostId':\n",
    "                row[2], # 'VoteTypeId': \n",
    "#                 'CreationDate': row[3],\n",
    "#               'UserId': row[4], \n",
    "#                 'BountyAmount': row[5]\n",
    "            ]\n",
    "            bucket.append(temp)\n",
    "        \n",
    "with open('/Users/chaizhizhi/Desktop/5338Assignment/Neo4jCypher/vote.csv','w') as post:\n",
    "        write_post = csv.writer(post,delimiter=',',quotechar='\"')\n",
    "        header = ['Id','PostId','VoteTypeId']\n",
    "        write_post.writerow(header)\n",
    "        write_post.writerows(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess user\n",
    "bucket = []\n",
    "with open(\"/Users/chaizhizhi/Desktop/5338_data/Users.tsv\") as User:\n",
    "        read_User = csv.reader(User, delimiter='\\t',quotechar='\"')\n",
    "        next(read_User)\n",
    "        for row in read_User:\n",
    "            # 拼装语句\n",
    "            temp = [\n",
    "              row[0], #  'Id': \n",
    "#                     'Reputation': row[1], \n",
    "                    row[2], #'CreationDate': \n",
    "                     row[3], #'DisplayName':\n",
    "#                     'LastAccessDate': row[4], \n",
    "#                     'Location': row[5], \n",
    "#                     'Views': row[6], \n",
    "                  row[7],#  'UpVotes': \n",
    "                    row[8],  #'DownVotes': \n",
    "#                 'AccountId': row[9]\n",
    "            ]\n",
    "            bucket.append(temp)\n",
    "        \n",
    "with open('/Users/chaizhizhi/Desktop/5338Assignment/Neo4jCypher/user.csv','w') as post:\n",
    "        write_post = csv.writer(post,delimiter=',',quotechar='\"')\n",
    "        header =  ['Id','CreationDate','DisplayName','UpVotes','DownVotes']\n",
    "        write_post.writerow(header)\n",
    "        write_post.writerows(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['deep-network'], ['generalization'], ['neurons'], ['mindstorms'], ['intelligent-agent'], ['philosophy'], ['fuzzy-logic'], ['neural-networks'], ['image-recognition'], ['turing-test'], ['strong-ai'], ['weak-ai'], ['definitions'], ['singularity'], ['overfitting'], ['optimization'], ['emotional-intelligence'], ['genetic-algorithms'], ['machine-learning'], ['terminology'], ['markov-chain'], ['probabilistic'], ['performance'], ['hidden-layers'], ['history'], ['models'], ['legal'], ['programming-languages'], ['lisp'], ['statistical-ai'], ['heuristics'], ['search'], ['chess'], ['comparison'], ['unsupervised-learning'], ['classical-ai'], ['agi'], ['declarative-programming'], ['gofai'], ['symbolic-computing'], ['algorithm'], ['self-driving'], ['decision-theory'], ['incompleteness-theorems'], ['boltzmann-machine'], ['efficiency'], ['ultraintelligent-machine'], ['hypercomputation'], ['recurrent-neural-networks'], ['halting-problem'], ['training'], ['deep-learning'], ['convolutional-neural-networks'], ['deepdream'], ['neural-doodle'], ['math'], ['pattern-recognition'], ['natural-language'], ['computer-vision'], ['quantum-computing'], ['handwritten-characters'], ['new-ai'], ['natural-language-processing'], ['wordvector'], ['classification'], ['knowledge-representation'], ['time'], ['embodied-cognition'], ['intelligence-testing'], ['ethics'], ['research'], ['chat-bots'], ['human-inspired'], ['text-summarization'], ['watson'], ['storage'], ['lexical-recognition'], ['ai-community'], ['cyborg'], ['mlp'], ['hardware'], ['problem-solving'], ['world-knowledge'], ['backpropagation'], ['learning-theory'], ['artificial-neuron'], ['signal-processing'], ['implementation'], ['applications'], ['ai-design'], ['ocr'], ['gradient-descent'], ['robots'], ['architecture'], ['prediction'], ['neuromorphic-computing'], ['friendly-ai'], ['death'], ['reinforcement-learning'], ['healthcare'], ['biology'], ['deep-blue'], ['social'], ['reasoning'], ['multi-agent-systems'], ['minimax'], ['game-theory'], ['datasets'], ['real-time'], ['linear-regression'], ['action-recognition'], ['lstm'], ['cars'], ['gaming'], ['branching-factors'], ['deepmind'], ['language-processing'], ['genetic-programming'], ['cyberterrorism'], ['security'], ['challenges'], ['control-problem'], ['prolog'], ['evolutionary-algorithms'], ['computer-programming'], ['object-recognition'], ['keras'], ['learning-algorithms'], ['path-planning'], ['robotics'], ['detecting-patterns'], ['asimovs-laws'], ['nasa'], ['deepdreaming'], ['computational-linguistics'], ['structured-data'], ['voice-recognition'], ['reference-request'], ['logic'], ['thought-vectors'], ['ai-box'], ['human-like'], ['cognitive-science'], ['tensorflow'], ['expert-system'], ['untagged'], ['swarm-intelligence'], ['software-architecture'], ['game-ai'], ['hci'], ['google'], ['linear-algebra'], ['combinatorics'], ['dropout'], ['ai-safety'], ['value-alignment'], ['go'], ['intelligence-augmentation'], ['neo-luddism'], ['superintelligence'], ['htm'], ['combinatorial-games'], ['imperfect-information'], ['incomplete-information'], ['cfg'], ['poker'], ['deepstack'], ['perceptron'], ['russell-norvig'], ['knapsack-problem'], ['negamax'], ['artificial-consciousness'], ['sentience'], ['scene-classification'], ['rul'], ['facial-recognition'], ['getting-started'], ['python'], ['ai-basics'], ['automation'], ['ai-takeover'], ['fitness-functions'], ['q-learning'], ['praxis'], ['graphs'], ['software-evaluation'], ['pathfinding'], ['theorics'], ['hardware-evaluation'], ['matlab'], ['data-science'], ['alphago'], ['self-replication'], ['universal-constructor'], ['alphazero'], ['brain'], ['super-organism'], ['r'], ['node-js'], ['genes'], ['graph-coloring'], ['neat'], ['generative-model'], ['javascript'], ['spanish-language'], ['time-complexity'], ['course-evaluation'], ['java'], ['c++'], ['unassisted-learning'], ['norvig-russell'], ['disambiguation'], ['art-aesthetics'], ['ai-field'], ['open-source'], ['emergence'], ['sentiment-analysis'], ['self-play'], ['perfect-play'], ['early-stopping'], ['regularization'], ['wetware'], ['word2vec'], ['teaching-concepts'], ['autoencoders'], ['mythology-of-ai'], ['decision-tree'], ['chinese-room-argument'], ['semantics'], ['rationality'], ['intelligence'], ['brute-force'], ['bayes'], ['open-ai'], ['self-awareness'], ['sense'], ['concepts'], ['academia'], ['real-world'], ['soft-question'], ['ltsm'], ['feedforward'], ['som'], ['digital-rights'], ['dqn'], ['alphago-zero'], ['google-cloud'], ['confidence'], ['profession'], ['topology'], ['connectivity'], ['structure'], ['feedback'], ['graph-theory'], ['alpha-beta-pruning'], ['marketability'], ['tools'], ['svm'], ['collaboration'], ['creative-commons'], ['autonomous-vehicles'], ['checkers'], ['activation-function'], ['relu'], ['monte-carlo-tree-search'], ['risk-management'], ['cyborexis'], ['dimensionality'], ['sparse-features'], ['generative-adversarial-networks'], ['convergence'], ['categorical-data'], ['automated-theorem-proving'], ['long-short-term-memory'], ['attention'], ['sequence-modelling'], ['job-trends'], ['multi-armed-bandit'], ['predicting-ai-milestones'], ['resource-request'], ['value-iteration'], ['thought'], ['breadth-first-search'], ['discount-factor'], ['sigmoid'], ['survival'], ['simple-reflex-agents']]\n"
     ]
    }
   ],
   "source": [
    "#preprocess tags\n",
    "bucket = []\n",
    "with open(\"/Users/chaizhizhi/Desktop/5338_data/Tags.tsv\") as tag:\n",
    "        read_tag = csv.reader(tag, delimiter='\\t',quotechar='\"')\n",
    "        next(read_tag)\n",
    "        for row in read_tag:\n",
    "            temp = [\n",
    "#               row[0],  #'Id': \n",
    "                   row[1] # 'Tagname': \n",
    "#                     'Count': row[2],\n",
    "#                     'ExcerptPostId': row[3], \n",
    "#                     'WikiPostId': row[4] \n",
    "            ]\n",
    "            bucket.append(temp)\n",
    "        \n",
    "with open('/Users/chaizhizhi/Desktop/5338Assignment/Neo4jCypher/tag.csv','w') as post:\n",
    "        write_post = csv.writer(post,delimiter=',',quotechar='\"')\n",
    "        header =  ['topic']\n",
    "        write_post.writerow(header)\n",
    "        write_post.writerows(bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pandas will lead to lots of problem. Give up to using pandas since it will generate NaN when read the data.\n",
    "All coloumns with NaN will be converted into float which will bring big trouble\n",
    "'''\n",
    "post_old = pd.read_csv(\"/Users/chaizhizhi/Desktop/5338_data/Posts.tsv\", encoding='UTF-8', sep=\"\\t\", quotechar='\"', dayfirst=True)\n",
    "vote_old = pd.read_csv(\"/Users/chaizhizhi/Desktop/5338_data/Votes.tsv\", encoding='UTF-8', sep=\"\\t\", quotechar='\"', dayfirst=True)\n",
    "user_old = pd.read_csv(\"/Users/chaizhizhi/Desktop/5338_data/Users.tsv\", encoding='UTF-8', sep=\"\\t\", quotechar='\"', dayfirst=True)\n",
    "tag_old = pd.read_csv(\"/Users/chaizhizhi/Desktop/5338_data/Tags.tsv\", encoding='UTF-8', sep=\"\\t\", quotechar='\"', dayfirst=True)\n",
    "#preprocess post, pick some columns\n",
    "post_old.columns\n",
    "# post_old['OwnerUserId'].fillna('0')\n",
    "# post_old['OwnerUserId'].astype(int)\n",
    "post_col = ['Id','PostTypeId','AcceptedAnswerId','CreationDate','ViewCount','OwnerUserId','Title','Tags','ParentId']\n",
    "post = pd.DataFrame(post_old[post_col])\n",
    "post.to_csv('post.csv',index= False)\n",
    "\n",
    "#preprocess vote\n",
    "vote_old.columns\n",
    "vote_col = ['Id','PostId','VoteTypeId']\n",
    "vote = pd.DataFrame(vote_old[vote_col])\n",
    "vote.to_csv('vote.csv',index=False)\n",
    "\n",
    "#preprocess user\n",
    "user_old.columns\n",
    "user_col = ['Id','CreationDate','DisplayName','UpVotes','DownVotes']\n",
    "user = pd.DataFrame(user_old[user_col])\n",
    "user.to_csv('user.csv',index=False)\n",
    "\n",
    "#Preprocess tag\n",
    "tag_old.columns\n",
    "tag_col = ['TagName']\n",
    "tag = pd.DataFrame(tag_old[tag_col])\n",
    "tag.to_csv('tag.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
